# AP 5

## 1 c) Create a pl/pgSQL code that inserts 10K tuples in table Products. Use the function rand to create values for price and stock.

# Solução para o item (c) - Inserir 10.000 tuplas na tabela Products

Aqui está um código PL/pgSQL que insere 10.000 registros na tabela `products`, utilizando valores aleatórios para `price` e `stock`:

```sql
DO $$
DECLARE
    i INTEGER;
    product_name TEXT;
    random_price NUMERIC(10,2);
    random_stock INTEGER;
BEGIN
    FOR i IN 1..10000 LOOP
        -- Gerar nome do produto
        product_name := 'Product ' || i;
        
        -- Gerar preço aleatório entre 1.00 e 1000.00
        random_price := 1 + (random() * 999);
        random_price := ROUND(random_price, 2);
        
        -- Gerar estoque aleatório entre 0 e 1000
        random_stock := FLOOR(random() * 1001);
        
        -- Inserir o registro
        INSERT INTO products (product_name, price, stock)
        VALUES (product_name, random_price, random_stock);
    END LOOP;
END $$;
```

## Explicação:

1. Usamos um bloco `DO` para executar código PL/pgSQL anônimo
2. Declaramos variáveis para:
   - Contador (`i`)
   - Nome do produto (`product_name`)
   - Preço aleatório (`random_price`)
   - Estoque aleatório (`random_stock`)
3. O loop `FOR` executa 10.000 iterações (de 1 a 10000)
4. Para cada iteração:
   - Geramos um nome de produto sequencial ("Product 1", "Product 2", etc.)
   - Geramos um preço aleatório entre 1.00 e 1000.00 usando `random()`
   - Arredondamos o preço para 2 casas decimais com `ROUND`
   - Geramos um estoque aleatório entre 0 e 1000 usando `FLOOR` para garantir valores inteiros
   - Inserimos o registro na tabela

Observação: A função `random()` retorna um valor entre 0.0 e 1.0, por isso fazemos os ajustes para obter os intervalos desejados. 

## 1  d) In your opinion, how might the active database concept apply to a table like products?

The **active database** concept can be effectively applied to a `products` table to automate business rules, maintain data integrity, and trigger real-time actions based on changes in product data. Here’s how it might apply:

---

### **1. Triggers for Automated Actions**
PostgreSQL triggers can enforce rules or cascade updates when products are modified. Examples:
- **Stock Replenishment**: Automatically reorder products when stock falls below a threshold.
  ```sql
  CREATE OR REPLACE FUNCTION check_stock()
  RETURNS TRIGGER AS $$
  BEGIN
    IF NEW.stock < 10 THEN
      INSERT INTO orders_to_supplier(product_id, quantity)
      VALUES (NEW.product_id, 100); -- Order 100 units
    END IF;
    RETURN NEW;
  END;
  $$ LANGUAGE plpgsql;

  CREATE TRIGGER stock_alert
  AFTER UPDATE OF stock ON products
  FOR EACH ROW EXECUTE FUNCTION check_stock();
  ```

- **Price Change Auditing**: Log price updates to track fluctuations.
  ```sql
  CREATE TABLE price_audit (
    product_id INT,
    old_price NUMERIC(10,2),
    new_price NUMERIC(10,2),
    change_time TIMESTAMP
  );

  CREATE OR REPLACE FUNCTION log_price_change()
  RETURNS TRIGGER AS $$
  BEGIN
    IF NEW.price <> OLD.price THEN
      INSERT INTO price_audit
      VALUES (OLD.product_id, OLD.price, NEW.price, NOW());
    END IF;
    RETURN NEW;
  END;
  $$ LANGUAGE plpgsql;

  CREATE TRIGGER price_audit_trigger
  AFTER UPDATE OF price ON products
  FOR EACH ROW EXECUTE FUNCTION log_price_change();
  ```

---

### **2. Constraints for Immediate Integrity Checks**
Active databases enforce rules at the moment of data modification:
- **Prevent Negative Stock** (already in your `CREATE TABLE`):
  ```sql
  CHECK (stock >= 0)
  ```
- **Validate Discounts**: Ensure sale prices don’t drop below cost.
  ```sql
  ALTER TABLE products ADD COLUMN cost NUMERIC(10,2);
  ALTER TABLE products ADD CHECK (price >= cost);
  ```

---

### **3. Event-Driven Notifications**
Use `LISTEN/NOTIFY` to alert external systems when products change:
```sql
CREATE OR REPLACE FUNCTION notify_price_change()
RETURNS TRIGGER AS $$
BEGIN
  PERFORM pg_notify(
    'price_updates',
    JSON_BUILD_OBJECT(
      'product_id', NEW.product_id,
      'new_price', NEW.price
    )::TEXT
  );
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER price_notification
AFTER UPDATE OF price ON products
FOR EACH ROW EXECUTE FUNCTION notify_price_change();
```
External apps can subscribe to the `price_updates` channel.

---

### **4. Materialized Views for Derived Data**
Automatically cache aggregated data (e.g., average price, total stock value):
```sql
CREATE MATERIALIZED VIEW product_stats AS
SELECT 
  COUNT(*) AS total_products,
  AVG(price) AS avg_price,
  SUM(stock) AS total_stock
FROM products;

-- Refresh after bulk updates:
REFRESH MATERIALIZED VIEW product_stats;
```

---

### **5. Rule-Based Discounts**
Dynamic pricing based on conditions (e.g., seasonal sales):
```sql
CREATE OR REPLACE FUNCTION apply_discount()
RETURNS VOID AS $$
BEGIN
  UPDATE products
  SET price = price * 0.9  -- 10% discount
  WHERE stock > 50 AND price > 100;  -- Criteria
END;
$$ LANGUAGE plpgsql;

-- Run during sales events:
SELECT apply_discount();
```

---

### **Why It Matters for `products`**
- **Real-Time Responsiveness**: Triggers/reactivity avoid manual checks.
- **Consistency**: Constraints/rules prevent invalid states (e.g., negative stock).
- **Auditability**: Logs track who changed what and when.
- **Scalability**: Notifications and materialized views reduce app-layer work.

Active databases turn PostgreSQL into a "self-managing" system for e-commerce, inventory, or analytics use cases.

## 2. Scalar Functions.

### (a) Write the code for the following scalar function:
```sql
CREATE OR REPLACE FUNCTION discount_price(
base_price NUMERIC,
discount_percent NUMERIC
)
...
```

Here's the code for the `discount_price` scalar function in PostgreSQL:

```sql
CREATE OR REPLACE FUNCTION discount_price(
    base_price NUMERIC,
    discount_percent NUMERIC
)
RETURNS NUMERIC AS $$
DECLARE
    discounted_price NUMERIC;
BEGIN
    -- Validate inputs
    IF base_price <= 0 THEN
        RAISE EXCEPTION 'Base price must be greater than 0';
    END IF;
    
    IF discount_percent < 0 OR discount_percent > 100 THEN
        RAISE EXCEPTION 'Discount percent must be between 0 and 100';
    END IF;
    
    -- Calculate discounted price
    discounted_price := base_price * (1 - (discount_percent / 100));
    
    -- Ensure the result doesn't go below 0
    discounted_price := GREATEST(discounted_price, 0);
    
    -- Round to 2 decimal places for currency
    discounted_price := ROUND(discounted_price, 2);
    
    RETURN discounted_price;
END;
$$ LANGUAGE plpgsql;
```

### Key Features:
1. **Input Validation**: Checks for invalid prices or discount percentages
2. **Discount Calculation**: Applies the percentage discount to the base price
3. **Price Floor Protection**: Ensures the result never goes below 0
4. **Currency Formatting**: Rounds to 2 decimal places
5. **Error Handling**: Raises exceptions for invalid inputs

### Example Usage:
```sql
SELECT discount_price(100, 20);  -- Returns 80.00 (20% off 100)
SELECT discount_price(50, 10.5); -- Returns 44.75 (10.5% off 50)
SELECT discount_price(200, 0);   -- Returns 200.00 (0% discount)
```

### c) Test the function

# Comprehensive Testing for the `discount_price` Function

```sql
-- Test cases for discount_price function

-- 1. Normal cases with whole numbers
SELECT 
    'Normal case: 20% off $100' AS test_case,
    discount_price(100, 20) AS result,
    CASE WHEN discount_price(100, 20) = 80.00 THEN 'PASS' ELSE 'FAIL' END AS status;

SELECT 
    'Normal case: 15% off $75' AS test_case,
    discount_price(75, 15) AS result,
    CASE WHEN discount_price(75, 15) = 63.75 THEN 'PASS' ELSE 'FAIL' END AS status;

-- 2. Decimal discounts
SELECT 
    'Decimal discount: 12.5% off $80' AS test_case,
    discount_price(80, 12.5) AS result,
    CASE WHEN discount_price(80, 12.5) = 70.00 THEN 'PASS' ELSE 'FAIL' END AS status;

-- 3. Edge cases
SELECT 
    '0% discount (no change)' AS test_case,
    discount_price(100, 0) AS result,
    CASE WHEN discount_price(100, 0) = 100.00 THEN 'PASS' ELSE 'FAIL' END AS status;

SELECT 
    '100% discount (free)' AS test_case,
    discount_price(100, 100) AS result,
    CASE WHEN discount_price(100, 100) = 0.00 THEN 'PASS' ELSE 'FAIL' END AS status;

-- 4. Minimum price protection
SELECT 
    'Discount doesnt make price negative' AS test_case,
    discount_price(10, 110) AS result,
    CASE WHEN discount_price(10, 110) = 0.00 THEN 'PASS' ELSE 'FAIL' END AS status;

-- 5. Rounding verification
SELECT 
    'Rounding check: 33.333% off $100' AS test_case,
    discount_price(100, 33.333) AS result,
    CASE WHEN discount_price(100, 33.333) = 66.67 THEN 'PASS' ELSE 'FAIL' END AS status;

-- 6. Error condition tests (should raise exceptions)
DO $$
BEGIN
    BEGIN
        -- Negative base price
        PERFORM discount_price(-50, 10);
        RAISE NOTICE 'Negative price test: FAIL (should have raised exception)';
    EXCEPTION WHEN OTHERS THEN
        RAISE NOTICE 'Negative price test: PASS (%)', SQLERRM;
    END;
    
    BEGIN
        -- Negative discount percent
        PERFORM discount_price(100, -5);
        RAISE NOTICE 'Negative discount test: FAIL (should have raised exception)';
    EXCEPTION WHEN OTHERS THEN
        RAISE NOTICE 'Negative discount test: PASS (%)', SQLERRM;
    END;
    
    BEGIN
        -- Discount > 100%
        PERFORM discount_price(100, 150);
        RAISE NOTICE '>100% discount test: FAIL (should have raised exception)';
    EXCEPTION WHEN OTHERS THEN
        RAISE NOTICE '>100% discount test: PASS (%)', SQLERRM;
    END;
END $$;
```

## Test Coverage Explanation:

1. **Normal Cases**:
   - Standard discounts (20% off $100)
   - Different base amounts (15% off $75)

2. **Decimal Discounts**:
   - Tests proper handling of fractional percentages (12.5%)

3. **Edge Cases**:
   - 0% discount (price remains unchanged)
   - 100% discount (price goes to zero)

4. **Price Floor Protection**:
   - Ensures price never goes negative (110% discount)

5. **Rounding Verification**:
   - Checks proper rounding to 2 decimal places

6. **Error Conditions**:
   - Negative base price (should raise exception)
   - Negative discount percent (should raise exception)
   - Discount > 100% (should raise exception)

The test script outputs both the calculated results and PASS/FAIL status for each test case, with the error condition tests using exception handling to verify proper validation.

## 3. Scalar Functions.

### (a) Create a function that asserts that a database field (e.g. product’s name) does not contain the special character (passed as an array parameter).

Here's a PostgreSQL function that checks if a specified database field contains any of the special characters passed in an array parameter:

```sql
CREATE OR REPLACE FUNCTION assert_no_special_chars(
    p_table_name TEXT,
    p_column_name TEXT,
    p_id_column TEXT,
    p_id_value INTEGER,
    p_special_chars TEXT[]
) RETURNS BOOLEAN AS $$
DECLARE
    v_field_value TEXT;
    v_contains_special BOOLEAN := FALSE;
    v_char TEXT;
    v_query TEXT;
BEGIN
    -- Build and execute dynamic query to get the field value
    v_query := format('SELECT %I FROM %I WHERE %I = $1', p_column_name, p_table_name, p_id_column);
    EXECUTE v_query INTO v_field_value USING p_id_value;
    
    -- Check if the field contains any of the special characters
    FOREACH v_char IN ARRAY p_special_chars LOOP
        IF v_field_value LIKE '%' || v_char || '%' THEN
            v_contains_special := TRUE;
            EXIT; -- Exit loop early if we find a match
        END IF;
    END LOOP;
    
    -- Raise exception if special characters found
    IF v_contains_special THEN
        RAISE EXCEPTION 'Field % in table % (ID: %) contains forbidden special characters (%)', 
                        p_column_name, p_table_name, p_id_value, p_special_chars;
    END IF;
    
    RETURN NOT v_contains_special;
END;
$$ LANGUAGE plpgsql;
```

### Usage Examples:

1. **Check a specific product**:
```sql
SELECT assert_no_special_chars(
    'products',          -- table name
    'product_name',      -- column to check
    'product_id',        -- ID column
    123,                 -- ID value
    ARRAY['@', '#', '$'] -- forbidden characters
);
```

2. **Use in a trigger** (to prevent inserts/updates with special chars):
```sql
CREATE OR REPLACE FUNCTION check_product_name_chars()
RETURNS TRIGGER AS $$
BEGIN
    PERFORM assert_no_special_chars(
        'products',
        'product_name',
        'product_id',
        NEW.product_id,
        ARRAY['@', '#', '$', '!'] -- your forbidden characters
    );
    RETURN NEW;
EXCEPTION WHEN OTHERS THEN
    RAISE EXCEPTION 'Product name validation failed: %', SQLERRM;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_check_product_name
BEFORE INSERT OR UPDATE ON products
FOR EACH ROW EXECUTE FUNCTION check_product_name_chars();
```

### Key Features:

1. **Dynamic SQL** - Works with any table and column
2. **Array parameter** - Accepts multiple special characters to check
3. **Secure formatting** - Uses `format()` with `%I` for identifiers to prevent SQL injection
4. **Early exit** - Stops checking when first forbidden character is found
5. **Detailed error** - Reports which field/table/ID failed validation

### Alternative Version (Returns Boolean Without Exception):

```sql
CREATE OR REPLACE FUNCTION contains_no_special_chars(
    p_text_to_check TEXT,
    p_special_chars TEXT[]
) RETURNS BOOLEAN AS $$
DECLARE
    v_char TEXT;
BEGIN
    FOREACH v_char IN ARRAY p_special_chars LOOP
        IF p_text_to_check LIKE '%' || v_char || '%' THEN
            RETURN FALSE;
        END IF;
    END LOOP;
    RETURN TRUE;
END;
$$ LANGUAGE plpgsql IMMUTABLE;
```

This simpler version just checks a text value against the character array, returning TRUE if no special chars are found.

### Explain why you choose the data types for the parameters and any of the constructions used in the function body.

Here's a detailed explanation of the data type choices and key constructions in the function, with specific technical rationale:

### Parameter Data Types

1. **`p_table_name TEXT` / `p_column_name TEXT` / `p_id_column TEXT`**
   - *Why TEXT?* PostgreSQL's `TEXT` is ideal for object identifiers because:
     - Handles any length (safer than VARCHAR with length limits)
     - Compatible with `format()` function's `%I` identifier placeholder
     - More flexible than `name` type which has length restrictions

2. **`p_id_value INTEGER`**
   - *Why INTEGER?* Assumes standard SERIAL primary keys
   - Could be made more flexible with:
     ```sql
     p_id_value ANYELEMENT  -- For mixed-type IDs (UUID, BIGINT, etc.)
     ```
   - Requires modifying the EXECUTE to use `USING p_id_value::TEXT` with dynamic casting

3. **`p_special_chars TEXT[]`**
   - *Why TEXT array?* 
     - Arrays allow passing multiple characters in a single parameter
     - More efficient than comma-separated strings (avoids splitting)
     - Enables clean `FOREACH` loop iteration
     - Alternative would be JSONB, but arrays are more natural for this use case

### Function Body Constructions

1. **Dynamic SQL with `format()`**
   ```sql
   format('SELECT %I FROM %I WHERE %I = $1', p_column_name, p_table_name, p_id_column)
   ```
   - `%I` automatically quotes identifiers safely (SQL injection protection)
   - `$1` parameter placeholder works with `USING` clause for value safety

2. **`FOREACH` Loop**
   ```sql
   FOREACH v_char IN ARRAY p_special_chars LOOP
   ```
   - More readable than iterating with array subscripts
   - PostgreSQL optimizes array iteration internally
   - Early `EXIT` when match found improves efficiency

3. **Exception Handling**
   ```sql
   RAISE EXCEPTION 'Field % in table % (ID: %) contains...' 
   ```
   - Explicit error messages help debugging
   - Uses `%` placeholders for safe message construction
   - Contrast with concatenation (`||`) which risks SQL injection

4. **Boolean Return Pattern**
   ```sql
   RETURN NOT v_contains_special;
   ```
   - Clear true/false semantics
   - Alternative design could return TEXT with error details

### Security Considerations

1. **Identifier Injection Protection**
   - Never use string concatenation (`||`) for identifiers
   - Always use `format()` with `%I` or `quote_ident()`

2. **Value Injection Protection**
   - `USING` clause in `EXECUTE` prevents value SQL injection
   - Alternative unsafe approach:
     ```sql
     -- UNSAFE! Do not use:
     EXECUTE 'SELECT... WHERE id = ' || p_id_value;
     ```

### Performance Optimizations

1. **Short-Circuit Evaluation**
   - `EXIT` when first bad character found
   - Avoids scanning entire string unnecessarily

2. **Immutable Alternative**
   - The second (simpler) function is marked `IMMUTABLE` because:
     - Pure text processing
     - No table access
     - Can be used in indexes for validation

This design balances safety, flexibility, and performance while adhering to PostgreSQL best practices.

### c) Properly test the function with different actual parameters for each of the functions’ formal parameters.

# Comprehensive Testing for the `assert_no_special_chars` Function

Here's a complete test suite that validates all parameters and edge cases:

## Test Setup
```sql
-- Create test table
CREATE TABLE test_products (
    product_id SERIAL PRIMARY KEY,
    product_name TEXT,
    description TEXT
);

-- Insert test data
INSERT INTO test_products (product_name, description) VALUES
('NormalProduct', 'Regular product description'),
('Product@Special', 'Contains @ character'),
('Product#Hash', 'Contains # tag'),
('Dollar$Product', 'Has $ symbol'),
('Multi!Char@Product', 'Multiple special chars');
```

## Test Cases

### 1. Basic Functionality Test
```sql
-- Should pass (no forbidden chars)
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    1, 
    ARRAY['@','#','$','!']
) AS test1_result;

-- Should fail (contains @)
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    2, 
    ARRAY['@','#','$','!']
) AS test2_result;
```

### 2. Column Parameter Variations
```sql
-- Test different column (description)
-- Should pass (description has no special chars for product_id 1)
SELECT assert_no_special_chars(
    'test_products', 
    'description', 
    'product_id', 
    1, 
    ARRAY['@','#','$','!']
) AS test3_result;

-- Should fail (description for product_id 2 contains @)
SELECT assert_no_special_chars(
    'test_products', 
    'description', 
    'product_id', 
    2, 
    ARRAY['@']
) AS test4_result;
```

### 3. Special Character Array Variations
```sql
-- Single special char to check
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    3, 
    ARRAY['#']
) AS test5_result;

-- Multiple special chars (one present)
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    4, 
    ARRAY['%','$','^']
) AS test6_result;

-- Empty array (should always pass)
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    1, 
    ARRAY[]::TEXT[]
) AS test7_result;
```

### 4. Edge Case Testing
```sql
-- Test with NULL field value (should pass)
INSERT INTO test_products (product_name) VALUES (NULL);
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    6, 
    ARRAY['@']
) AS test8_result;

-- Test with empty string (should pass)
INSERT INTO test_products (product_name) VALUES ('');
SELECT assert_no_special_chars(
    'test_products', 
    'product_name', 
    'product_id', 
    7, 
    ARRAY['@']
) AS test9_result;
```

### 5. Error Condition Testing
```sql
-- Test invalid table name
DO $$
BEGIN
    PERFORM assert_no_special_chars(
        'nonexistent_table', 
        'product_name', 
        'product_id', 
        1, 
        ARRAY['@']
    );
    RAISE NOTICE 'Invalid table test: FAILED (should raise exception)';
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE 'Invalid table test: PASSED (%)', SQLERRM;
END $$;

-- Test invalid column name
DO $$
BEGIN
    PERFORM assert_no_special_chars(
        'test_products', 
        'nonexistent_column', 
        'product_id', 
        1, 
        ARRAY['@']
    );
    RAISE NOTICE 'Invalid column test: FAILED (should raise exception)';
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE 'Invalid column test: PASSED (%)', SQLERRM;
END $$;

-- Test invalid ID
DO $$
BEGIN
    PERFORM assert_no_special_chars(
        'test_products', 
        'product_name', 
        'product_id', 
        999, 
        ARRAY['@']
    );
    RAISE NOTICE 'Invalid ID test: FAILED (should raise exception)';
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE 'Invalid ID test: PASSED (%)', SQLERRM;
END $$;
```

## Test Results Verification

For automated verification, you can use this summary query:

```sql
SELECT 
    test_case,
    expected_result,
    actual_result,
    CASE WHEN expected_result = actual_result THEN 'PASS' ELSE 'FAIL' END AS status
FROM (
    VALUES
        ('Basic test - no special chars', true, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',1,ARRAY['@','#','$','!']))),
        ('Basic test - with special char', false, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',2,ARRAY['@','#','$','!']) IS NULL)),
        ('Different column test', true, 
            (SELECT assert_no_special_chars('test_products','description','product_id',1,ARRAY['@','#','$','!']))),
        ('Single char array test', false, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',3,ARRAY['#']) IS NULL)),
        ('Empty array test', true, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',1,ARRAY[]::TEXT[]))),
        ('NULL field test', true, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',6,ARRAY['@']))),
        ('Empty string test', true, 
            (SELECT assert_no_special_chars('test_products','product_name','product_id',7,ARRAY['@'])))
) AS tests(test_case, expected_result, actual_result);
```

This comprehensive test suite:
1. Validates all function parameters
2. Tests both success and failure cases
3. Covers edge cases (NULL, empty strings)
4. Verifies error handling
5. Includes automated result verification

The tests demonstrate that the function:
- Correctly identifies special characters
- Handles different columns and tables
- Processes various special character arrays
- Properly manages edge cases
- Fails appropriately for invalid inputs

### Add the constraint to the products table using alter table command. The constraint must use the function created in 3a to see if name do not include @ and #.

# Adding Constraint to Products Table

To add a constraint that uses the `assert_no_special_chars` function to prevent `@` and `#` characters in product names, use this command:

```sql
ALTER TABLE products
ADD CONSTRAINT no_special_chars_in_name
CHECK (
    assert_no_special_chars(
        'products',         -- Table name
        'product_name',     -- Column to check
        'product_id',       -- ID column name
        product_id,         -- Current row's ID (no quotes)
        ARRAY['@', '#']     -- Forbidden characters
    )
);
```

## Key Points:

1. **Constraint Name**: `no_special_chars_in_name` identifies the constraint

2. **Function Parameters**:
   - `'products'` - The table containing the data
   - `'product_name'` - The column being validated
   - `'product_id'` - The primary key column
   - `product_id` - The current row's ID value (note no quotes)
   - `ARRAY['@', '#']` - The special characters to prohibit

3. **Behavior**:
   - Automatically validates on INSERT and UPDATE
   - Raises an exception if the check fails
   - Works with existing and new data

4. **Testing the Constraint**:

```sql
-- This will succeed (no special chars)
INSERT INTO products (product_name, price, stock)
VALUES ('Regular Product', 19.99, 50);

-- This will fail (contains @)
INSERT INTO products (product_name, price, stock)
VALUES ('Special@Product', 24.99, 30);

-- This will fail (contains #)
UPDATE products
SET product_name = 'New#Product'
WHERE product_id = 1;
```

## Alternative Version (More Efficient):

If you prefer a solution that doesn't require the function for each check:

```sql
ALTER TABLE products
ADD CONSTRAINT no_special_chars_in_name_simple
CHECK (product_name !~ '[@#]');
```

This simpler version uses a regular expression pattern match directly in the CHECK constraint.

--- 

## 4. Set Functions.

### (a) Create a function that takes an interval of values as parameters and returns all products that are in stock and whose price is within the interval.

# Function to Find Products Within Price Range and In Stock

Here's a PostgreSQL function that returns products within a specified price range that are in stock:

```sql
CREATE OR REPLACE FUNCTION get_products_in_price_range(
    min_price NUMERIC(10,2),
    max_price NUMERIC(10,2)
)
RETURNS TABLE (
    product_id INTEGER,
    product_name VARCHAR(100),
    price NUMERIC(10,2),
    stock INTEGER
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.product_name,
        p.price,
        p.stock
    FROM 
        products p
    WHERE 
        p.price BETWEEN min_price AND max_price
        AND p.stock > 0
    ORDER BY 
        p.price;
END;
$$ LANGUAGE plpgsql;
```

## Key Features:

1. **Parameters**:
   - `min_price`: The lower bound of the price range
   - `max_price`: The upper bound of the price range

2. **Returns**:
   - A table with product details (ID, name, price, stock)
   - Only products with stock > 0
   - Products ordered by price (ascending)

3. **Usage Examples**:

```sql
-- Get products between $10 and $50 that are in stock
SELECT * FROM get_products_in_price_range(10.00, 50.00);

-- Get all products under $100 in stock
SELECT * FROM get_products_in_price_range(0.01, 100.00);
```

## Enhanced Version (with Additional Parameters):

```sql
CREATE OR REPLACE FUNCTION get_filtered_products(
    min_price NUMERIC(10,2) DEFAULT 0.01,
    max_price NUMERIC(10,2) DEFAULT 999999.99,
    min_stock INTEGER DEFAULT 1
)
RETURNS TABLE (
    product_id INTEGER,
    product_name VARCHAR(100),
    price NUMERIC(10,2),
    stock INTEGER,
    price_category TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.product_name,
        p.price,
        p.stock,
        CASE
            WHEN p.price < 20 THEN 'Budget'
            WHEN p.price BETWEEN 20 AND 100 THEN 'Standard'
            ELSE 'Premium'
        END AS price_category
    FROM 
        products p
    WHERE 
        p.price BETWEEN min_price AND max_price
        AND p.stock >= min_stock
    ORDER BY 
        p.price;
END;
$$ LANGUAGE plpgsql;
```

## Usage of Enhanced Version:

```sql
-- Get all in-stock products (default parameters)
SELECT * FROM get_filtered_products();

-- Get products between $50-$200 with at least 5 in stock
SELECT * FROM get_filtered_products(50.00, 200.00, 5);

-- Get premium products only (price > $100)
SELECT * FROM get_filtered_products(100.01) WHERE price_category = 'Premium';
```

The function provides flexible filtering options while ensuring only available products are returned.

### b) Properly test the function with different actual parameters for each of the functions’ formal parameters.

# Comprehensive Test Suite for `get_products_in_price_range` Function

## Test Setup
First, let's populate the products table with test data:

```sql
-- Clear existing test data (if any)
TRUNCATE products RESTART IDENTITY;

-- Insert test products
INSERT INTO products (product_name, price, stock) VALUES
('Budget Item A', 9.99, 10),
('Budget Item B', 14.99, 0),    -- Out of stock
('Standard Item X', 49.99, 5),
('Premium Product 1', 199.99, 3),
('Premium Product 2', 249.99, 0), -- Out of stock
('Clearance Item', 4.99, 100),
('Luxury Item', 999.99, 2);
```

## Test Cases

### 1. Basic Range Tests
```sql
-- Test 1: Products between $10-$50 (should return Standard Item X only)
SELECT * FROM get_products_in_price_range(10.00, 50.00);

-- Test 2: All products under $20 (should return Budget Item A and Clearance Item)
SELECT * FROM get_products_in_price_range(0.01, 19.99);

-- Test 3: Premium range $100-$300 (should return Premium Product 1 only)
SELECT * FROM get_products_in_price_range(100.00, 300.00);
```

### 2. Edge Case Tests
```sql
-- Test 4: Exact price point (should return Premium Product 1)
SELECT * FROM get_products_in_price_range(199.99, 199.99);

-- Test 5: Range with no matches (should return empty)
SELECT * FROM get_products_in_price_range(500.00, 600.00);

-- Test 6: Range where all items are out of stock (should return empty)
SELECT * FROM get_products_in_price_range(200.00, 250.00);
```

### 3. Boundary Tests
```sql
-- Test 7: Minimum possible price (should return Clearance Item)
SELECT * FROM get_products_in_price_range(0.01, 5.00);

-- Test 8: Very high range (should return Luxury Item)
SELECT * FROM get_products_in_price_range(500.00, 1000.00);

-- Test 9: Full range (all in-stock items)
SELECT * FROM get_products_in_price_range(0.01, 1000.00);
```

### 4. Invalid Parameter Tests
```sql
-- Test 10: min_price > max_price (should return empty)
SELECT * FROM get_products_in_price_range(50.00, 10.00);

-- Test 11: Negative prices (should return empty as no products match)
SELECT * FROM get_products_in_price_range(-10.00, -1.00);

-- Test 12: Zero stock threshold (edge case)
-- First temporarily add a product with exactly 0 stock but in our test data we already have some
SELECT * FROM get_products_in_price_range(0.01, 1000.00) WHERE stock = 0;
```

## Automated Test Verification

For automated testing, you can use this validation query:

```sql
SELECT 
    test_id,
    test_description,
    expected_count,
    actual_count,
    CASE WHEN expected_count = actual_count THEN 'PASS' ELSE 'FAIL' END AS status
FROM (
    SELECT 1 AS test_id, 'Products $10-$50' AS test_description, 1 AS expected_count,
        (SELECT COUNT(*) FROM get_products_in_price_range(10.00, 50.00)) AS actual_count
    UNION ALL
    SELECT 2, 'Products under $20', 2,
        (SELECT COUNT(*) FROM get_products_in_price_range(0.01, 19.99))
    UNION ALL
    SELECT 3, 'Premium range $100-$300', 1,
        (SELECT COUNT(*) FROM get_products_in_price_range(100.00, 300.00))
    UNION ALL
    SELECT 4, 'Exact price point $199.99', 1,
        (SELECT COUNT(*) FROM get_products_in_price_range(199.99, 199.99))
    UNION ALL
    SELECT 5, 'No matches $500-$600', 0,
        (SELECT COUNT(*) FROM get_products_in_price_range(500.00, 600.00))
    UNION ALL
    SELECT 6, 'All out of stock $200-$250', 0,
        (SELECT COUNT(*) FROM get_products_in_price_range(200.00, 250.00))
) AS test_cases
ORDER BY test_id;
```

## Enhanced Function Testing

For the enhanced version with more parameters:

```sql
-- Test 13: Default parameters (all in-stock items)
SELECT * FROM get_filtered_products();

-- Test 14: Minimum stock requirement
SELECT * FROM get_filtered_series(0.01, 1000.00, 5);  -- Only items with stock ≥ 5

-- Test 15: Price category filtering
SELECT * FROM get_filtered_products() WHERE price_category = 'Budget';

-- Test 16: Combined filters
SELECT * FROM get_filtered_products(50.00, 300.00, 2) 
WHERE price_category IN ('Standard', 'Premium');
```

This comprehensive test suite:
1. Validates normal operation with various price ranges
2. Tests edge cases and boundary conditions
3. Verifies handling of invalid parameters
4. Includes automated result verification
5. Covers both basic and enhanced function versions

The tests confirm the function correctly:
- Filters by price range
- Excludes out-of-stock items
- Handles edge cases properly
- Returns expected result formats

### (c) Discuss some of the advantages of functions that return sets and present examples that illustrate each of the advantages found.

# Advantages of Set-Returning Functions in PostgreSQL

Set-returning functions (functions that return tables or multiple rows) offer several powerful advantages in database programming. Here's a detailed discussion with illustrative examples:

## 1. **Encapsulation of Complex Logic**

**Advantage**: Bundles complex queries into reusable units that maintain data integrity.

**Example**:
```sql
CREATE OR REPLACE FUNCTION get_high_value_customers(min_purchase NUMERIC)
RETURNS TABLE (
    customer_id INT,
    customer_name TEXT,
    total_spent NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT c.id, c.name, SUM(o.amount)
    FROM customers c
    JOIN orders o ON c.id = o.customer_id
    GROUP BY c.id
    HAVING SUM(o.amount) >= min_purchase;
END;
$$ LANGUAGE plpgsql;

-- Usage
SELECT * FROM get_high_value_customers(1000);
```

## 2. **Dynamic Result Generation**

**Advantage**: Can generate rows programmatically without physical tables.

**Example** (Date series generator):
```sql
CREATE OR REPLACE FUNCTION generate_dates(start_date DATE, end_date DATE)
RETURNS TABLE (calendar_date DATE) AS $$
BEGIN
    RETURN QUERY
    SELECT generate_series(start_date, end_date, '1 day')::DATE;
END;
$$ LANGUAGE plpgsql;

-- Usage
SELECT * FROM generate_dates('2023-01-01', '2023-01-07');
```

## 3. **Polymorphic Table Functions**

**Advantage**: Single function can return different column sets based on input.

**Example**:
```sql
CREATE OR REPLACE FUNCTION get_products_by_category(category_id INT)
RETURNS TABLE (
    product_id INT,
    product_name TEXT,
    price NUMERIC
) AS $$
BEGIN
    IF category_id IS NULL THEN
        RETURN QUERY SELECT id, name, price FROM products;
    ELSE
        RETURN QUERY 
        SELECT id, name, price 
        FROM products 
        WHERE category = category_id;
    END IF;
END;
$$ LANGUAGE plpgsql;

-- Usage
SELECT * FROM get_products_by_category(5);  -- Specific category
SELECT * FROM get_products_by_category(NULL);  -- All products
```

## 4. **Lazy Evaluation**

**Advantage**: Process large datasets efficiently by yielding rows as needed.

**Example** (Paginated results):
```sql
CREATE OR REPLACE FUNCTION get_products_paginated(
    page_num INT, 
    page_size INT
)
RETURNS TABLE (
    product_id INT,
    product_name TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT id, name
    FROM products
    ORDER BY name
    LIMIT page_size
    OFFSET (page_num - 1) * page_size;
END;
$$ LANGUAGE plpgsql;

-- Usage
SELECT * FROM get_products_paginated(2, 10);  -- Second page of 10 items
```

## 5. **Simplified Application Code**

**Advantage**: Moves complex joins and filters to the database layer.

**Example** (Multi-join report):
```sql
CREATE OR REPLACE FUNCTION get_customer_order_report()
RETURNS TABLE (
    customer_name TEXT,
    order_count INT,
    last_order_date DATE,
    total_spent NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT c.name, COUNT(o.id), MAX(o.order_date), SUM(o.amount)
    FROM customers c
    LEFT JOIN orders o ON c.id = o.customer_id
    GROUP BY c.id;
END;
$$ LANGUAGE plpgsql;

-- Usage (application just calls this instead of multiple queries)
SELECT * FROM get_customer_order_report();
```

## 6. **Security Abstraction**

**Advantage**: Provides controlled data access through functions rather than direct table access.

**Example** (Row-level security):
```sql
CREATE OR REPLACE FUNCTION get_my_orders()
RETURNS TABLE (
    order_id INT,
    order_date DATE,
    amount NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT id, order_date, amount
    FROM orders
    WHERE customer_id = current_user_id();  -- Hypothetical auth function
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Usage
SELECT * FROM get_my_orders();  -- Only shows current user's orders
```

## 7. **Composite Data Transformation**

**Advantage**: Can restructure and transform data before returning it.

**Example** (JSON processing):
```sql
CREATE OR REPLACE FUNCTION parse_events(json_data JSONB)
RETURNS TABLE (
    event_id UUID,
    event_name TEXT,
    event_time TIMESTAMP,
    is_active BOOLEAN
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        (elem->>'id')::UUID,
        elem->>'name',
        (elem->>'timestamp')::TIMESTAMP,
        (elem->>'active')::BOOLEAN
    FROM jsonb_array_elements(json_data) AS elem;
END;
$$ LANGUAGE plpgsql;

-- Usage
SELECT * FROM parse_events('[{"id": "...", "name": "Login", ...}]');
```

## Key Benefits Summary

1. **Improved Maintainability**: Complex queries are defined once
2. **Performance Optimization**: Push processing to database engine
3. **Consistent Security**: Centralized access control
4. **Reduced Network Traffic**: Filter data before transmission
5. **Flexible Interfaces**: Can adapt to different calling contexts

Set-returning functions are particularly valuable in:
- Reporting systems
- Data APIs
- Complex business logic implementations
- Data transformation pipelines
- Security-sensitive applications

--- 

## 5. Cursors in a PL/pgSQL

### (a) Write a function that uses a cursor to loop through product table and calculate total stock value.

# Function to Calculate Total Stock Value Using a Cursor

Here's a PostgreSQL function that uses a cursor to iterate through the products table and calculate the total value of all inventory in stock:

```sql
CREATE OR REPLACE FUNCTION calculate_total_stock_value()
RETURNS NUMERIC(12,2) AS $$
DECLARE
    product_cursor CURSOR FOR
        SELECT price, stock FROM products WHERE stock > 0;
    
    product_record RECORD;
    total_value NUMERIC(12,2) := 0;
BEGIN
    OPEN product_cursor;
    
    LOOP
        FETCH product_cursor INTO product_record;
        EXIT WHEN NOT FOUND;
        
        -- Calculate value for current product and add to total
        total_value := total_value + (product_record.price * product_record.stock);
    END LOOP;
    
    CLOSE product_cursor;
    
    RETURN total_value;
END;
$$ LANGUAGE plpgsql;
```

## Key Components Explained:

1. **Cursor Declaration**:
   ```sql
   product_cursor CURSOR FOR
       SELECT price, stock FROM products WHERE stock > 0;
   ```
   - Defines a cursor that selects only in-stock products
   - Retrieves just the columns we need (price and stock)

2. **Loop Structure**:
   ```sql
   LOOP
       FETCH product_cursor INTO product_record;
       EXIT WHEN NOT FOUND;
       -- Calculation logic
   END LOOP;
   ```
   - Fetches rows one at a time
   - Exits when no more rows are available

3. **Calculation**:
   ```sql
   total_value := total_value + (product_record.price * product_record.stock);
   ```
   - Multiplies price by stock quantity for each product
   - Accumulates the total value

## Alternative Version (Simpler Approach Without Cursor)

For comparison, here's how you could do this without a cursor:

```sql
CREATE OR REPLACE FUNCTION calculate_total_stock_value_simple()
RETURNS NUMERIC(12,2) AS $$
BEGIN
    RETURN COALESCE(
        (SELECT SUM(price * stock) FROM products WHERE stock > 0),
        0
    );
END;
$$ LANGUAGE plpgsql;
```

## When to Use the Cursor Version:

1. When you need to perform complex row-by-row processing
2. When you need to conditionally accumulate values
3. When learning cursor mechanics for more complex operations
4. When preparing to add additional per-row logic

## Testing the Function:

```sql
-- Insert test data
INSERT INTO products (product_name, price, stock) VALUES
('Product A', 10.00, 5),
('Product B', 25.50, 3),
('Product C', 100.00, 0),  -- Out of stock
('Product D', 7.99, 10);

-- Test the function
SELECT calculate_total_stock_value();
-- Expected result: (10*5) + (25.50*3) + (7.99*10) = 50 + 76.50 + 79.90 = 206.40

-- Test with empty table
TRUNCATE products;
SELECT calculate_total_stock_value();  -- Should return 0
```

The cursor-based approach demonstrates fundamental database programming techniques that can be adapted for more complex inventory calculations, such as applying discounts by product category or calculating values for specific warehouses.

### (b) Test the function properly. What are the cases where you feel the need to test against? Why?

# Comprehensive Testing for the `calculate_total_stock_value` Function

To properly test the cursor-based stock value calculation function, we should evaluate several critical scenarios that verify both correctness and robustness.

## Test Cases and Rationale

### 1. **Basic Calculation Test**
```sql
-- Setup
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Widget A', 10.00, 5),    -- $50 value
('Widget B', 25.50, 3),     -- $76.50 value
('Widget C', 7.99, 10);     -- $79.90 value

-- Test (expected: 50 + 76.50 + 79.90 = 206.40)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Verifies basic arithmetic correctness with standard values.

### 2. **Zero Stock Items Test**
```sql
-- Setup
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Product X', 100.00, 0),   -- Should be excluded
('Product Y', 50.00, 1),    -- $50 value
('Product Z', 75.00, 0);    -- Should be excluded

-- Test (expected: 50.00)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Confirms the cursor properly skips out-of-stock items (stock = 0).

### 3. **Precision Handling Test**
```sql
-- Setup
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Penny Item', 0.99, 1000), -- $990 value
('Fractional', 19.999, 3);  -- Should round to $60.00 (19.999 * 3 = 59.997 → 60.00)

-- Test (expected: 990.00 + 60.00 = 1050.00)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Verifies proper decimal/NUMERIC handling and rounding.

### 4. **Empty Table Test**
```sql
-- Setup
TRUNCATE products;

-- Test (expected: 0.00)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Ensures the function handles empty tables gracefully.

### 5. **Large Numbers Test**
```sql
-- Setup
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Bulk Item', 999999.99, 9999);  -- ~9.99 billion value

-- Test (verify no overflow)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Confirms the NUMERIC(12,2) return type handles large values.

### 6. **Negative Price Validation**
```sql
-- Setup (should never happen due to table constraints)
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Invalid Item', -10.00, 5);  -- -$50 "value"

-- Test (expected: -50.00, though constraints should prevent this)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Demonstrates why CHECK constraints are important (though the function would still work).

### 7. **Mixed Case Test**
```sql
-- Setup
TRUNCATE products;
INSERT INTO products (product_name, price, stock) VALUES
('Item 1', 10.00, 0),
('Item 2', 15.00, 2),   -- $30
('Item 3', 20.00, 0),
('Item 4', 100.00, 1),  -- $100
('Item 5', 5.00, 10);   -- $50

-- Test (expected: 30 + 100 + 50 = 180.00)
SELECT calculate_total_stock_value() AS total_value;
```
**Why**: Complex scenario testing interleaved in-stock/out-of-stock items.

## Automated Test Suite

For comprehensive validation, use this test script:

```sql
DO $$
DECLARE
    test_name TEXT;
    actual NUMERIC(12,2);
    expected NUMERIC(12,2);
    test_count INT := 0;
    pass_count INT := 0;
BEGIN
    -- Test 1: Basic calculation
    TRUNCATE products;
    INSERT INTO products VALUES (1,'Test1',10.00,5),(2,'Test2',25.50,3),(3,'Test3',7.99,10);
    actual := calculate_total_stock_value();
    expected := 206.40;
    test_count := test_count + 1;
    IF actual = expected THEN
        pass_count := pass_count + 1;
        RAISE NOTICE 'Test 1 Passed: Basic calculation';
    ELSE
        RAISE NOTICE 'Test 1 Failed: Expected %, got %', expected, actual;
    END IF;

    -- Test 2: Zero stock items
    TRUNCATE products;
    INSERT INTO products VALUES (1,'Test1',100.00,0),(2,'Test2',50.00,1),(3,'Test3',75.00,0);
    actual := calculate_total_stock_value();
    expected := 50.00;
    test_count := test_count + 1;
    IF actual = expected THEN
        pass_count := pass_count + 1;
        RAISE NOTICE 'Test 2 Passed: Zero stock handling';
    ELSE
        RAISE NOTICE 'Test 2 Failed: Expected %, got %', expected, actual;
    END IF;

    -- Test 3: Empty table
    TRUNCATE products;
    actual := calculate_total_stock_value();
    expected := 0.00;
    test_count := test_count + 1;
    IF actual = expected THEN
        pass_count := pass_count + 1;
        RAISE NOTICE 'Test 3 Passed: Empty table';
    ELSE
        RAISE NOTICE 'Test 3 Failed: Expected %, got %', expected, actual;
    END IF;

    -- Summary
    RAISE NOTICE 'Test results: % of % tests passed', pass_count, test_count;
END $$;
```

## Key Testing Considerations

1. **Boundary Conditions**: Testing zero, one, and many products
2. **Edge Cases**: Very large numbers, decimal precision
3. **Logical Validation**: Correct filtering of out-of-stock items
4. **Error Scenarios**: Empty table handling
5. **Arithmetic Accuracy**: Proper multiplication and summation

The cursor implementation requires thorough testing because:
- It processes rows sequentially (different execution path than set-based operations)
- Accumulates state (total_value variable)
- Implicitly filters data (WHERE stock > 0 in cursor definition)

These tests verify both the business logic (correct inventory valuation) and the technical implementation (cursor mechanics).

### (c) Compare the cursor-based approach to a single SQL query.

# Comparison: Cursor-Based vs. Single SQL Query Approach

## Performance Characteristics

### Cursor-Based Approach
```sql
CREATE OR REPLACE FUNCTION calculate_total_stock_value_cursor()
RETURNS NUMERIC(12,2) AS $$
DECLARE
    product_cursor CURSOR FOR SELECT price, stock FROM products WHERE stock > 0;
    product_record RECORD;
    total_value NUMERIC(12,2) := 0;
BEGIN
    OPEN product_cursor;
    LOOP
        FETCH product_cursor INTO product_record;
        EXIT WHEN NOT FOUND;
        total_value := total_value + (product_record.price * product_record.stock);
    END LOOP;
    CLOSE product_cursor;
    RETURN total_value;
END;
$$ LANGUAGE plpgsql;
```

### Single SQL Query Approach
```sql
CREATE OR REPLACE FUNCTION calculate_total_stock_value_sql()
RETURNS NUMERIC(12,2) AS $$
BEGIN
    RETURN COALESCE(
        (SELECT SUM(price * stock) FROM products WHERE stock > 0),
        0.00
    );
END;
$$ LANGUAGE plpgsql;
```

## Key Differences

| Aspect                | Cursor-Based Approach                          | Single SQL Query Approach                  |
|-----------------------|-----------------------------------------------|--------------------------------------------|
| **Execution**         | Row-by-row processing                         | Set-based operation                       |
| **Performance**       | Slower (network roundtrips for each row)      | Faster (single operation)                 |
| **Memory Usage**      | Lower (processes one row at a time)           | Higher (may materialize intermediate set) |
| **Locking Behavior**  | Holds locks longer                            | Releases locks quickly                    |
| **Readability**       | More verbose                                  | More concise                             |
| **Flexibility**       | Can add complex per-row logic                 | Limited to SQL expressions               |
| **Scalability**       | Poor for large tables                         | Excellent for large tables               |

## When to Use Each Approach

### Use Cursor When:
1. You need **row-by-row processing** with complex logic
2. You're **modifying data** during iteration
3. You need to **conditionally accumulate** values
4. Processing **very large rowsets** that can't fit in memory

### Use Single SQL Query When:
1. You need **aggregate calculations** (like this sum)
2. **Performance is critical**
3. You're doing **read-only operations**
4. The logic can be **expressed in pure SQL**

## Performance Benchmark

```sql
-- Create test table with 10,000 products
TRUNCATE products;
INSERT INTO products (product_name, price, stock)
SELECT 
    'Product '||n, 
    (random()*1000)::NUMERIC(10,2), 
    (random()*100)::INT
FROM generate_series(1,10000) n;

-- Test cursor approach
EXPLAIN ANALYZE SELECT calculate_total_stock_value_cursor();
-- Typical result: Execution time: ~150-200ms

-- Test SQL approach
EXPLAIN ANALYZE SELECT calculate_total_stock_value_sql();
-- Typical result: Execution time: ~5-10ms
```

## Real-World Example Where Cursor Shines

```sql
-- Applying dynamic discounts by category requires row-by-row logic
CREATE OR REPLACE FUNCTION apply_category_discounts()
RETURNS VOID AS $$
DECLARE
    prod_cursor CURSOR FOR 
        SELECT p.product_id, p.price, c.discount 
        FROM products p JOIN categories c ON p.category_id = c.id;
    prod RECORD;
BEGIN
    OPEN prod_cursor;
    LOOP
        FETCH prod_cursor INTO prod;
        EXIT WHEN NOT FOUND;
        
        -- Complex business logic
        IF prod.discount > 0 THEN
            UPDATE products 
            SET price = price * (1 - prod.discount/100)
            WHERE product_id = prod.product_id;
        END IF;
    END LOOP;
    CLOSE prod_cursor;
END;
$$ LANGUAGE plpgsql;
```

## Conclusion

For **this specific inventory valuation task**, the single SQL query is:
- **10-20x faster**
- **More readable**
- **More maintainable**
- **More scalable**

Reserve cursors for cases requiring:
- Per-row procedural logic
- Data modification during iteration
- Conditional processing that can't be expressed in SQL

The cursor version serves as a good learning tool but should be replaced with set-based operations in production when possible.

### (d) In what scenarios could a cursor-based approach be beneficial vs. a single SQL aggregation?

# Scenarios Where Cursor-Based Approaches Outperform Single SQL Aggregations

While single SQL aggregations are generally preferred for performance, there are specific scenarios where cursor-based processing provides distinct advantages:

## 1. Complex Row-by-Row Processing

**When**: Each row requires procedural logic that can't be expressed in pure SQL

**Example**: Applying multi-step business rules to each product
```sql
CREATE OR REPLACE FUNCTION process_inventory_adjustments()
RETURNS VOID AS $$
DECLARE
    prod_cursor CURSOR FOR 
        SELECT product_id, stock, price FROM products FOR UPDATE;
    current RECORD;
    new_stock INT;
BEGIN
    OPEN prod_cursor;
    LOOP
        FETCH prod_cursor INTO current;
        EXIT WHEN NOT FOUND;
        
        -- Complex business logic
        IF current.stock < 5 THEN
            new_stock := current.stock + 10; -- Restock
        ELSIF current.price > 100 AND current.stock > 20 THEN
            new_stock := current.stock - 5; -- Reduce overstock
        ELSE
            new_stock := current.stock;
        END IF;
        
        UPDATE products SET stock = new_stock
        WHERE product_id = current.product_id;
    END LOOP;
    CLOSE prod_cursor;
END;
$$ LANGUAGE plpgsql;
```

## 2. Conditional Accumulation with State

**When**: Calculations require maintaining state between rows

**Example**: Running balance calculation with reset conditions
```sql
CREATE OR REPLACE FUNCTION calculate_category_running_totals()
RETURNS TABLE(category_id INT, product_id INT, running_total NUMERIC) AS $$
DECLARE
    cur CURSOR FOR 
        SELECT category_id, product_id, price 
        FROM products 
        ORDER BY category_id, product_id;
    current RECORD;
    last_category INT := NULL;
    running_sum NUMERIC := 0;
BEGIN
    OPEN cur;
    LOOP
        FETCH cur INTO current;
        EXIT WHEN NOT FOUND;
        
        IF last_category IS DISTINCT FROM current.category_id THEN
            running_sum := 0; -- Reset for new category
            last_category := current.category_id;
        END IF;
        
        running_sum := running_sum + current.price;
        RETURN NEXT (current.category_id, current.product_id, running_sum);
    END LOOP;
    CLOSE cur;
END;
$$ LANGUAGE plpgsql;
```

## 3. Data Modification During Iteration

**When**: You need to read and modify data in the same transaction

**Example**: Recursive inventory processing
```sql
CREATE OR REPLACE FUNCTION process_inventory_chain_reaction()
RETURNS VOID AS $$
DECLARE
    cur CURSOR FOR 
        SELECT product_id, stock FROM products 
        WHERE needs_processing = TRUE FOR UPDATE;
    current RECORD;
BEGIN
    OPEN cur;
    LOOP
        FETCH cur INTO current;
        EXIT WHEN NOT FOUND;
        
        -- Process may affect other rows
        PERFORM process_dependent_items(current.product_id);
        
        UPDATE products 
        SET needs_processing = FALSE 
        WHERE product_id = current.product_id;
    END LOOP;
    CLOSE cur;
END;
$$ LANGUAGE plpgsql;
```

## 4. External System Integration

**When**: Calling external APIs or services during processing

**Example**: Validating products against external inventory service
```sql
CREATE OR REPLACE FUNCTION sync_with_external_inventory()
RETURNS INT AS $$
DECLARE
    cur CURSOR FOR SELECT product_id, stock FROM products;
    current RECORD;
    external_stock INT;
    mismatch_count INT := 0;
BEGIN
    OPEN cur;
    LOOP
        FETCH cur INTO current;
        EXIT WHEN NOT FOUND;
        
        -- Call external web service
        external_stock := get_external_inventory(current.product_id);
        
        IF external_stock != current.stock THEN
            UPDATE products SET stock = external_stock
            WHERE product_id = current.product_id;
            mismatch_count := mismatch_count + 1;
        END IF;
    END LOOP;
    CLOSE cur;
    
    RETURN mismatch_count;
END;
$$ LANGUAGE plpgsql;
```

## 5. Hierarchical/Graph Data Processing

**When**: Processing tree structures or complex graphs

**Example**: Bill of materials explosion
```sql
CREATE OR REPLACE FUNCTION calculate_component_costs(root_id INT)
RETURNS NUMERIC AS $$
DECLARE
    cur CURSOR FOR 
        WITH RECURSIVE bom_tree AS (...)
        SELECT * FROM bom_tree;
    current RECORD;
    total_cost NUMERIC := 0;
BEGIN
    OPEN cur;
    LOOP
        FETCH cur INTO current;
        EXIT WHEN NOT FOUND;
        
        -- Complex cost accumulation logic
        total_cost := total_cost + 
            (current.component_cost * current.quantity * 
             get_location_factor(current.warehouse_id));
    END LOOP;
    CLOSE cur;
    
    RETURN total_cost;
END;
$$ LANGUAGE plpgsql;
```

## When to Choose Cursors Over Aggregations

1. **Non-SQL Operations Needed**: When you need IF/THEN logic, function calls, or procedural processing
2. **Side Effects Required**: When processing affects other systems or requires row-level locking
3. **Stateful Calculations**: When computations depend on previous row values
4. **External Integration**: When calling APIs or external services during processing
5. **Complex Error Handling**: When different rows need different error handling approaches

## Performance Considerations

Even in these scenarios, consider:
- Using **FAST FORWARD** (read-only) cursors when possible
- Adding **WHERE CURRENT OF** for positioned updates
- Limiting cursor scope with **FETCH 100** for batch processing
- Exploring **window functions** for running calculations before resorting to cursors

Cursor-based approaches should be used judiciously - only when the problem truly requires row-by-row processing that can't be solved with set operations.

---

## 7. Reflection & Wrap-up

### (a) Why might using a scalar function in a large SELECT degrade performance?

# Performance Impact of Scalar Functions in Large SELECT Queries

Scalar functions can significantly degrade performance in large SELECT operations due to several key factors:

## 1. **Row-by-Row Execution (RBAR)**
- Scalar functions execute **once per row** rather than in bulk
- For 1M rows, the function runs 1M times vs. set-based processing
- Example:
  ```sql
  SELECT product_id, format_price(price)  -- Called per row
  FROM products
  WHERE category = 'Electronics';
  ```

## 2. **Optimizer Limitations**
- Query planner often can't optimize across function boundaries
- Statistics and indexes inside functions become invisible to the outer query
- Example:
  ```sql
  SELECT product_id 
  FROM products
  WHERE is_expensive(price, category);  -- Index on price won't help
  ```

## 3. **Context Switching Overhead**
- Each function call requires:
  - Parameter marshaling
  - Execution plan switching
  - Result marshaling back
- Measurable as "function evaluation cost" in execution plans

## 4. **Parallelization Barriers**
- Functions often prevent parallel query execution
- Forces serial processing even on multi-core systems
- Example plan shows `Gather` node stopping at function call:
  ```
  ->  Function Scan on is_expensive
        SubPlan 1
  ```

## 5. **Memory Consumption**
- Each function invocation maintains its own execution context
- Memory overhead compounds with large row counts
- Can lead to tempdb spills in SQL Server or OOM in PostgreSQL

## 6. **Predicate Pushdown Prevention**
- Filters can't be pushed inside function logic
- Forces full table scans when partial scans would suffice
- Example:
  ```sql
  SELECT * FROM orders
  WHERE is_recent_order(order_date);  -- Can't use order_date index effectively
  ```

## Performance Comparison

### Without Function (Set-Based)
```sql
-- Processes 1M rows in a single operation
SELECT product_id, price * 0.9 AS discounted_price
FROM products
WHERE category = 'Electronics';
```
**Execution**: ~100ms for 1M rows

### With Scalar Function
```sql
-- Processes 1M rows individually
SELECT product_id, apply_discount(price) 
FROM products
WHERE category = 'Electronics';
```
**Execution**: ~10,000ms for same 1M rows (100x slower)

## When Scalar Functions ARE Appropriate

1. **Small result sets** (< 1000 rows)
2. **Complex calculations** that can't be expressed in pure SQL
3. **Infrequently executed queries** (reports, not OLTP)
4. **Data masking/formatting** in final presentation layer

## Optimization Strategies

1. **Inline the Logic**:
   ```sql
   -- Instead of:
   SELECT apply_discount(price) FROM products;
   
   -- Use:
   SELECT price * CASE WHEN... END FROM products;
   ```

2. **Use Table-Valued Functions**:
   ```sql
   -- Set-based processing
   SELECT p.*, d.discounted_price
   FROM products p
   CROSS APPLY calculate_discounts(p.price) d;
   ```

3. **Materialize Intermediate Results**:
   ```sql
   -- Pre-calculate in temp table
   WITH discounted AS (
     SELECT product_id, price * 0.9 AS discounted_price
     FROM products
   )
   SELECT * FROM discounted WHERE...;
   ```

4. **Mark Functions as LEAKPROOF/IMMUTABLE** (PostgreSQL):
   ```sql
   CREATE FUNCTION format_price(numeric) RETURNS text
   IMMUTABLE LEAKPROOF  -- Helps optimization
   AS $$...$$;
   ```

The performance impact grows exponentially with row count, making scalar functions particularly problematic for large datasets in analytical queries or reporting systems.

### (b) How does a cursor differ from a normal SELECT in terms of resource usage?

# Cursor vs. Normal SELECT: Resource Usage Comparison

Cursors and normal SELECT statements differ significantly in how they utilize database resources, with important implications for performance and scalability:

## Memory Usage

**Normal SELECT**:
- Loads the **entire result set** into memory (or tempdb if large)
- Single memory allocation for all rows
- Example: A 1M row query consumes memory for all 1M rows at once

**Cursor**:
- Typically holds only **one row at a time** in memory
- Smaller memory footprint per connection
- Example: A 1M row cursor only needs memory for the current row

*Exception*: Some cursors (like static/insensitive) materialize the full result set

## CPU Utilization

**Normal SELECT**:
- Single execution plan
- Optimized set-based processing
- Parallel execution possible (multi-core utilization)

**Cursor**:
- **Per-row overhead** for each FETCH
- No parallelization
- Example: Processing 1M rows requires 1M FETCH operations

## Locking Behavior

**Normal SELECT**:
- Locks released immediately after scan
- Snapshot isolation minimizes blocking

**Cursor**:
- May hold **locks longer** (especially with FOR UPDATE)
- Scroll locks maintain position
- Example: A cursor iterating through orders could block other transactions

## Network Traffic

**Normal SELECT**:
- Single roundtrip for full result set
- Bulk data transfer

**Cursor**:
- **Multiple roundtrips** (one per FETCH)
- Chatty protocol overhead
- Example: 1M rows = 1M network requests vs. 1 for normal SELECT

## Temporary Storage

**Normal SELECT**:
- May spill to tempdb only if very large

**Cursor**:
- Static/keyset cursors often **materialize full results** in tempdb
- Example: A 10GB cursor result creates 10GB tempdb usage

## PostgreSQL-Specific Behavior

**Declaration**:
```sql
-- Normal SELECT (set-based)
SELECT * FROM large_table WHERE condition;

-- Cursor (row-based)
BEGIN;
DECLARE cur CURSOR FOR SELECT * FROM large_table WHERE condition;
FETCH 1 FROM cur; -- Process row
-- ... repeat ...
CLOSE cur;
COMMIT;
```

## Performance Comparison

| Operation          | Normal SELECT (1M rows) | Cursor (1M rows) |
|--------------------|------------------------|------------------|
| Memory             | High (all rows)         | Low (per row)    |
| CPU                | Optimized bulk          | Per-row overhead |
| Locks              | Short duration          | Long duration    |
| Network            | 1 roundtrip             | 1M roundtrips    |
| Execution Time     | Seconds                 | Minutes          |

## When Cursors Are Appropriate

1. **Row-by-row processing** that can't be set-based
2. **Client-side paging** (FETCH 100 rows at a time)
3. **Data modification** during iteration (WHERE CURRENT OF)
4. **Procedural logic** requiring state between rows

## Optimization Tips

1. Use **NO SCROLL** cursors when possible
2. Specify **FAST_FORWARD** for read-only operations
3. **FETCH** multiple rows at once (e.g., FETCH 100)
4. Consider **temp tables** as an alternative
5. In PostgreSQL, use **FOR UPDATE SKIP LOCKED** for queues

Cursors should be used judiciously - their per-row overhead makes them unsuitable for large-scale data processing where set operations would suffice.

### (c) In the context of PL/pgSQL, how does the choice of datatypes for variables and function parameters impact performance, and what are some common pitfalls associated with their misuse? Provide examples to illustrate your points.

# Data Type Choices in PL/pgSQL: Performance Impacts and Common Pitfalls

The selection of data types in PL/pgSQL significantly affects performance and correctness. Here's a detailed analysis with practical examples:

## Performance Impacts of Data Type Choices

### 1. Numeric Precision Overhead
**Problem**: Using `NUMERIC` when `INTEGER` would suffice
```sql
-- Slower due to arbitrary precision math
CREATE FUNCTION calc_total(numeric, numeric) RETURNS numeric AS $$
BEGIN
    RETURN $1 * $2;
END;
$$ LANGUAGE plpgsql;

-- Faster with integer types
CREATE FUNCTION calc_total(int, int) RETURNS int AS $$
BEGIN
    RETURN $1 * $2;
END;
$$ LANGUAGE plpgsql;
```
*Benchmark*: Integer operations are 2-3x faster than numeric in PostgreSQL.

### 2. Text Handling
**Problem**: Unconstrained `TEXT` vs. sized `VARCHAR`
```sql
-- Less efficient for indexing
CREATE FUNCTION process_name(name TEXT) RETURNS TEXT AS $$...$$;

-- More efficient when max length known
CREATE FUNCTION process_name(name VARCHAR(100)) RETURNS VARCHAR(100) AS $$...$$;
```
*Impact*: Sized types help the optimizer estimate memory requirements.

### 3. Boolean vs. Integer Flags
**Problem**: Using integers for boolean logic
```sql
-- Less clear and potentially slower
CREATE FUNCTION is_active(status INT) RETURNS INT AS $$
BEGIN
    RETURN CASE WHEN status = 1 THEN 1 ELSE 0 END;
END;
$$ LANGUAGE plpgsql;

-- Proper boolean usage
CREATE FUNCTION is_active(active BOOLEAN) RETURNS BOOLEAN AS $$
BEGIN
    RETURN active;
END;
$$ LANGUAGE plpgsql;
```

## Common Pitfalls and Examples

### 1. Implicit Casting Overhead
**Pitfall**: Mismatched types forcing runtime conversions
```sql
CREATE FUNCTION find_orders(order_ids TEXT[]) RETURNS SETOF orders AS $$
DECLARE
    id INT;  -- Mismatch with TEXT[] parameter
BEGIN
    FOREACH id IN ARRAY order_ids LOOP  -- Implicit cast happens here
        RETURN QUERY SELECT * FROM orders WHERE order_id = id;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```
*Fix*: Match array element types exactly.

### 2. Unnecessary Large Types
**Pitfall**: Using BIGINT for small value ranges
```sql
CREATE FUNCTION get_user_level(user_id BIGINT) RETURNS BIGINT AS $$
-- Will consume 8 bytes per ID when INT (4 bytes) would suffice
```

### 3. Parameter Type Mismatches
**Pitfall**: Function parameters not matching table columns
```sql
CREATE FUNCTION update_price(item_id INT, new_price NUMERIC(10,4)) RETURNS VOID AS $$
BEGIN
    -- Fails if prices table has NUMERIC(10,2) column
    UPDATE prices SET price = new_price WHERE id = item_id;
END;
$$ LANGUAGE plpgsql;
```
*Solution*: Mirror the exact column types.

### 4. Composite Type Misuse
**Pitfall**: Overusing row-type variables
```sql
CREATE FUNCTION process_order(order_id INT) RETURNS VOID AS $$
DECLARE
    full_order orders%ROWTYPE;  -- Loads all columns when maybe not needed
BEGIN
    SELECT * INTO full_order FROM orders WHERE id = order_id;
    -- Only using 2-3 fields but fetched all columns
END;
$$ LANGUAGE plpgsql;
```
*Better*: Declare only needed fields.

### 5. Array Type Selection
**Pitfall**: Using text arrays for numeric data
```sql
CREATE FUNCTION sum_values(values TEXT[]) RETURNS NUMERIC AS $$
DECLARE
    total NUMERIC := 0;
BEGIN
    FOR i IN 1..array_length(values, 1) LOOP
        total := total + values[i]::NUMERIC;  -- Costly per-element cast
    END LOOP;
    RETURN total;
END;
$$ LANGUAGE plpgsql;
```
*Better*: Use `NUMERIC[]` directly.

## Performance Optimization Tips

1. **Match Column Types Exactly**:
   ```sql
   -- Good
   CREATE FUNCTION update_product(
       id INT, 
       price NUMERIC(10,2)  -- Matches products.price column
   ) AS $$...$$;
   ```

2. **Use Domain Types for Validation**:
   ```sql
   CREATE DOMAIN email_type AS TEXT 
   CHECK (VALUE ~ '^[^@]+@[^@]+\.[^@]+$');
   
   CREATE FUNCTION send_notification(email email_type) AS $$...$$;
   ```

3. **Consider ENUM Types for Fixed Sets**:
   ```sql
   CREATE TYPE order_status AS ENUM ('new', 'processing', 'shipped');
   
   CREATE FUNCTION update_status(
       order_id INT, 
       status order_status  -- More efficient than TEXT
   ) AS $$...$$;
   ```

4. **Use STRICT for Parameter Handling**:
   ```sql
   CREATE FUNCTION safe_divide(a INT, b INT) RETURNS INT AS $$
   BEGIN
       RETURN a / b;  -- Will error on null or division by zero
   END;
   $$ LANGUAGE plpgsql STRICT;  -- Returns NULL if any parameter is NULL
   ```

The most common performance issues stem from type conversions and unnecessarily large data types. Always match your variable declarations to the underlying table column types when interacting with database objects.
