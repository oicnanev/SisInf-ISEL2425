# Test4

Run in *pgadmin query tool* the text from the file ```/Test4/init.sql```

```sql
/*
 *   ISEL-DEETC-SisInf
 *   ND 2022-2025
 *
 *   Didactic material to support the course
 *   Information Systems
 *   
 *   Based on examples from Prof. Walter Vieira
 */

--S0 -> Step 0

--BEGIN S0  Run BEFORE EVERY EXERCISE
drop table if exists conta;

create table conta(
   id integer primary key,
   saldo real
);

start transaction;
  insert into conta values(1111,1000);
  insert into conta values(2222,2000);
commit;
select * from conta;
-- END S0
```

Output:

|"id"|"saldo"|
|----|-------|
|1111|1000|
|2222|2000|

---

Then, from the file ```/Test4/Utilizador1.sql``` run:

```sql
-- S1
-- S1:
begin transaction;
--set transaction isolation level read committed;
set transaction isolation level repeatable read;
```

Output:

```txt
SET

Query returned successfully in 42 msec.
```
---

From file ```/Test4/Utilizador2.sql``` run:

```sql
-- S2
insert into conta values(3333,0);
```

Output:

```txt
INSERT 0 1

Query returned successfully in 27 msec.
```

---

Returning to file ```/Test4/Utilizador1.sql``` run:

```sql
-- S3:
select  avg(saldo) from conta where saldo > 500;
```

Output:

|"avg"|
|-----|
|1500|

---

Back again to ```/Test4/Utilizador2.sql``` and run:

```sql
--S4
insert into conta values(4444,5000);
```

Output:

```txt
INSERT 0 1

Query returned successfully in 21 msec.
```

---

And, returning to ```/Test4/Utilizador1.sql```, run:

```sql
-- S5
select avg(saldo) from conta where saldo > 500;
```

Output:

|"avg"|
|-----|
|1500|

```sql
commit;
```

Output:

```txt
COMMIT

Query returned successfully in 24 msec.
```

## Questions:

### Have you observed any of the anomalies studied? Why was it observed and how would you eliminate it?

#### Observed Anomaly: Phantom Read Prevention

In this scenario, we observed a demonstration of how the **REPEATABLE READ** isolation level prevents phantom reads, which is actually the expected behavior rather than an anomaly.

##### Sequence of Events:

1. User1 starts a transaction with **REPEATABLE READ** isolation level
2. User2 inserts a new row (3333, 0)
3. User1 calculates the average balance for accounts with saldo > 500 and gets 1500
4. User2 inserts another row (4444, 5000) which meets the condition saldo > 500
5. User1 repeats the same query (avg of saldo > 500) and still gets 1500, despite the addition of another qualifying row

##### Analysis:

This demonstrates how **REPEATABLE READ** isolation level works - it ensures that the same query executed multiple times within a transaction sees the same set of rows, even if other transactions commit new rows that would satisfy the query conditions.

In a standard scenario:
- The average for the first query should be 1500 (average of 1000 and 2000)
- After the insertion of row (4444, 5000), the average would typically be 2666.67 (average of 1000, 2000, and 5000)

However, User1 still sees only the original rows because of the repeatable read isolation level, which maintains a snapshot of the database from the start of the transaction.

##### This is not an anomaly, but expected behavior

The **REPEATABLE READ** isolation level is specifically designed to prevent phantom reads. A phantom read anomaly would have occurred if User1 could see the new row (4444, 5000) in the second query, which would make the results inconsistent between the two queries in the same transaction.

##### If we wanted to observe a phantom read anomaly:

The proper way to demonstrate a phantom read anomaly would be to:
1. Change User1's isolation level to **READ COMMITTED** instead of REPEATABLE READ
2. Execute the same sequence of operations
3. The second query would then return a different average that includes the new row

##### How to "eliminate" the behavior:

If we specifically wanted to see the new rows (which would actually be introducing the phantom read anomaly):

1. Change the isolation level for User1:

```sql
BEGIN TRANSACTION;
SET TRANSACTION ISOLATION LEVEL READ COMMITTED;
```

2. With READ COMMITTED, each query sees a fresh snapshot that includes all committed changes from other transactions, so the second query would reflect the new row with 5000 balance.

In production systems, the choice depends on requirements:
- Use REPEATABLE READ when we need query consistency within a transaction
- Use READ COMMITTED when we need to see the most up-to-date data, accepting that repeated queries might return different results

